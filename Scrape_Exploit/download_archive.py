import zipfile
import os
import urllib.request
import requests
from tqdm import tqdm
from progress.bar import Bar
from progress.spinner import Spinner
import sys
sys.path.append('/home/john/Project/CVE_crawler/')
from Configs.read_cfg import read_cfg


def download(url, dst):
    r = requests.get(url, stream=True)

    size = None
    while size is None:
        try:
            size = r.headers['content-length']
        except:
            r = requests.get(url, stream=True)

    if size:
        p = Bar('Downloading...', max=int(size))
    else:
        p = Spinner('Downloading...')

    with open(dst, 'wb') as f:
        for chunk in r.iter_content(chunk_size=1024*50):
            if chunk: # filter out keep-alive new chunks
                p.next(len(chunk))
                f.write(chunk)

    p.finish()

def download_and_unzip():

    cfg = read_cfg("paths")
    download_path = cfg["download_path"]
    extract_path = cfg["extract_path"]
    url = 'https://github.com/offensive-security/exploitdb/archive/master.zip'

    try:
        download(url, download_path)
  
        with zipfile.ZipFile(download_path, 'r') as zip_ref:
            for member in tqdm(zip_ref.infolist(), desc='Extracting '):
                try:
                    zip_ref.extract(member, extract_path)
                except zipfile.error as e:
                    pass

        if os.path.exists(download_path):
            os.remove(download_path)

    except ValueError as e:
            print(e)