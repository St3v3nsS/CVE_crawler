import re
import os
import time
import sys
sys.path.append('/home/john/Project/CVE_crawler/')
from Mongo_Connection import get_db as mongodb
from Scrapers.init_scrapers import add_scrapers
from Configs.read_cfg import read_cfg
from Loggers import logger

scrapers = add_scrapers()

cfg = read_cfg("mongodb")
collections = cfg["collections"]
path = read_cfg("paths")["exploits"]

db = mongodb.get_db()
collection = db[collections["parse_exp"]]
collection.create_index([("filename", 1)], unique=True)
cve_col = db[collections["cves"]]
ce = db[collections["ce"]]
ce.create_index([("filename", 1)], unique=True)
exploitdb = db[collections["exploitdb"]]
mitre_ref = db[collections["cve_refs"]]

dictionary = {}

start = time.time()


def parse_folder():
    for (root, dirs, files) in os.walk(path, topdown=True):
        for name in files:
            filename = os.path.join(root, name)

            with open(filename, encoding='utf-8') as f:
                exploit = f.read()

            exploit_type = root.split('/')[-1]
            name1, ext = os.path.splitext(name)

            platform_edb = None
            description_edb = None
            date = None
            edb = exploitdb.find_one({"filename": name})
            if edb is not None:
                description_edb = edb['title']
                platform_edb = edb['platform']
                date = edb['date']

            if dictionary.get(ext) is not None:
                dictionary[ext]['total'] += 1
            else:
                obj = {
                    "total": 1,
                    "filename": filename
                }
                dictionary[ext] = obj

            if ext == '.rb':
                metasploit = re.findall('(?:class Metasploit|msf/core)', exploit)  # Search for 'Metasploit' occurence
                if metasploit:
                    ext = '.metasploit'

            parser = scrapers.get(ext)
            if not parser:
                continue

            scraper = parser(filename, name1, exploit_type, description_edb, platform_edb, exploit, mongodb, date)
            scraper.parse_infos()
            scraper.logger.info(f"Done parsing {filename}")
    logger.myLogger("Scraper").info("Done all files!") 