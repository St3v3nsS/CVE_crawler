import re
import regex
from .scraper import Scraper


class SysScraper(Scraper):
    def __init__(self, filename=None, name=None, exploit_type=None, title=None, platform=None, exploit=None, mongoclient=None, date=None):
        ext = ['.sys']
        super().__init__(filename, name, exploit_type, title, platform, exploit, mongoclient, date, ext)

    def parse_infos(self):
        if self.is_parsed():
            return

        error = False
        parsed_file = True
        try:
            self.get_basic_ref()
            self.add_to("refs", re.findall(r'here:?\s*(.*?)\s', self.exploit))
            self.get_basic_target()

            URI = self.parse_url()
            self.update_db(URI)

        except Exception as e:
            error, parsed_file = self.found_error(e)

        finally:
            self.update_parsed_obj_db(parsed_file, error)

    def parse_url(self):
        URIs = ['/']

        try:
            URIs.extend(self.get_basic_url())
        except TimeoutError:
            pass
        try:
            URIs.extend(self.get_method_url())
        except TimeoutError:
            pass
        try:
            URIs.extend(regex.findall(r'http:\/\/.*?(\/.*?)[\s\\)\]"\'<]', self.exploit, timeout=5))
        except TimeoutError: pass

        return self.extract_url(URIs)
