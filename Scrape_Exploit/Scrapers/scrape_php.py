import re
import regex
from .scraper import Scraper


class PHPScraper(Scraper):
    def __init__(self, filename=None, name=None, exploit_type=None, title=None, platform=None, exploit=None, mongoclient=None, date=None):
        ext = ['.php', '.pph']
        super().__init__(filename, name, exploit_type, title, platform, exploit, mongoclient, date, ext)

    def parse_infos(self):
        if self.is_parsed():
            return

        error = False
        parsed_file = True
        try:
            comments = []
            if self.check_source_at_begin():
                if ('#' not in self.source_at_begin[2] or '#' not in self.source_at_begin[2]) or '<?' not in self.source_at_begin[2] \
                        or 'my' not in self.source_at_begin[2]:
                    self.add_to("description", ([self.source_at_begin[2]]))
                if (len(self.source_at_begin[1]) > 2 and '#' not in self.source_at_begin[3]) or '<?' not in self.source_at_begin[3] or 'my' not in self.source_at_begin[3]:
                    self.add_to("targets", ([self.source_at_begin[3]]))

            self.get_basic_ref()
            self.add_to("refs", re.findall(r'(?:based on|[sS]ee|[vV]isit|[pP]ublished at|[Mm]ore|site)\s*:?\s*(.*?)\s', self.exploit))
            comments.extend(re.findall(r'/\*(.*?)\*/', self.exploit, flags=re.S))
            comments.extend(re.findall(r'^//(.*?)\n\n', self.exploit, flags=re.S|re.M))
            comments.extend(re.findall(r'echo\s*\"(.*)\";', self.exploit))
            comments.extend(re.findall(r'^(#.*?)(?:<p|if|#\n\n)', self.exploit, flags=re.S|re.M))
            self.add_to("name", re.findall(r'<[tT][iI][tT][lL][eE]>(.*?)</', self.exploit))

            for comment in comments:
                self.get_basic_name(comment=comment)
                self.get_basic_version(comment=comment)
                self.add_to("description", (
                    re.findall(r'(?:[Dd]esc(?:ription)?|Summary)\s*:?\s*(.*?)\n\n', comment, flags=re.S | re.M)))
                self.add_to("refs", re.findall(r'References?:?\s*(.*?)\s', comment))
                self.add_to("refs", re.findall(r'(?:Software [lL]ink\s*|advisor(?:y|ies)):\s*(.*)', comment))
                self.add_to("targets", (re.findall(r'[Tt]ested\s*(?:on|with)\s*:?\s*(.*)', comment)))
                if re.findall(r'Sun-?\s*Tzu:', comment):
                    group = re.findall(r'#.*?\n#\s+#\n#\s*(.*?)\s*#\n#\s*(.*?)\s*#', comment)
                    if group and 'coded by' not in group[0][1]:
                        self.add_to("name", [group[0][0]+' ' + group[0][1]])

            URI = self.parse_url()
            self.update_db(URI)

        except Exception as e:
            error, parsed_file = self.founded_error(e)
        finally:
            self.update_parsed_obj_db(parsed_file, error)

    def parse_url(self):
        URIs = []

        self.exploit = re.sub(r'\$argv\[\d\]', '/', self.exploit)

        try:
            URIs.extend(self.get_basic_url())
        except TimeoutError:
            pass
        try:
            URIs.extend(self.get_method_url())
        except TimeoutError:
            pass
        try:
            URIs.extend(regex.findall(r'(\/[\/.a-zA-Z0-9-_]+)', self.exploit, timeout=5))
        except TimeoutError: pass
        try:
            URIs.extend(regex.findall(r'(?:GET|POST|PUT|PATCH|HEAD).*?\s*\"\s*\.?\s*?(.*)H', self.exploit, timeout=5))
        except TimeoutError: pass

        return self.extract_url(URIs)

