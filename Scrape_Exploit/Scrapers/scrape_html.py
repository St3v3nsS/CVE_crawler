import re
import regex
from .scraper import Scraper
from six import string_types

class HTMLParser(Scraper):
    def __init__(self, filename=None, name=None, exploit_type=None, title=None, platform=None, exploit=None, mongoclient=None, date=None):
        ext = ['.html', '.xhtml']
        super().__init__(filename, name, exploit_type, title, platform, exploit, mongoclient, date, ext)
    
    def parse_infos(self):
        if self.is_parsed():
            return

        error = False
        parsed_file = True
        try:
            new_comments = []

            self.exploit = re.sub(r'&\s*n\s*b\s*s\s*p\s*;', '', self.exploit)

            # Even if the name of exploit exists, I need it for finding other stuffs, but it will not be included in the json

            comments = re.findall(r'\/\*(.*?)\*\/', self.exploit, flags=re.S | re.M) # C-style comments
            html_comments = re.findall(r'<!?--(.*?)--!?>', self.exploit, flags=re.S | re.M)  # HTML comments
            if html_comments:
                value = re.findall(r'(.*)\n(?:http|[sS]ource:)', html_comments[0])
                if value and '==' not in value[0] and len(value[0]) > 0 and '**' not in value[0]:
                    self.add_to("name", [value[0]])
                if not self.extracted_object["name"]:
                    value = re.findall(r'\n(.*?)\n', html_comments[0], flags=re.M|re.S)
                    if value and '--' not in value[0] and '==' not in value[0]:
                        self.add_to("name", [value[0]])
                    if not self.extracted_object["name"]:
                        value = re.findall(r'(.*?)\n\n', html_comments[0], flags=re.M|re.S)
                        if value and '--' not in value[0]:
                            self.add_to("name", [value[0]])
                    else:
                        value = re.findall(r'--\n(.*?)\n\n', html_comments[0], flags=re.M|re.S)
                        if value and ('###' not in value[0] or '===' not in value[0]):
                            self.add_to("description", [value[0]])
                else:
                    value = re.findall(r'\n\n(.*?)\n\n', html_comments[0], flags=re.M|re.S)
                    if value and ('###' not in value[0] or '===' not in value[0]):
                        self.add_to("description", [value[0]])

            comments.append(html_comments)  # HTML comments
            if not re.findall(r'^<.*>', self.exploit, flags=re.S |re.M):  
                comments.append(re.sub(r'<[\w\s]+>(.*)</\w+>', '', self.exploit,flags= re.S | re.M))    # Take everything outside the < >
            else:
                comments.append(re.sub(r'^<.*>', '', self.exploit,flags= re.S | re.M))    # Take everything outside the < >

            comments.append(re.findall(r"//'=+(.*?)//'=+", self.exploit,flags= re.S | re.M)) # Some JS comments
            comments.append(re.findall(r'(?:##)+(.*)(?:##)+', self.exploit,flags= re.S | re.M))  # Some dashes

            self.add_to("name", re.findall(r'<[tT][iI][Tt][lLRr][eE]>(.*?)</[Tt][Ii][Tt][LlRr][Ee]>', self.exploit)) # <title>
            tuples = re.findall(r'(Netscape|Opera|Safari).*(Browser).*(\(V.*?\))', self.exploit, flags=re.S|re.M)
            if tuples:
                tuples = tuples[0]
                self.add_to("name", [tuples[0] + ' ' + tuples[1] + ' ' + tuples[2]])
                self.add_to("vversion", [tuples[0] + ' ' + tuples[1] + ' ' + tuples[2]])
                self.add_to("name", re.findall(r'<h\d.?>(.*?)</h\d>', self.exploit)) # headings

            for array in comments:  #   Make array from array of arrays
                if isinstance(array, string_types):
                    new_comments.append(array)
                else:
                    for comment in array:
                        new_comments.append(comment)

            for comment in new_comments:
                source_at_begin = re.findall(r'^[Ss]ource.*\s+(.*)\s+(.*)\s+([^#]+?)\n', comment) # For comments like source .. \n text \n text
                if source_at_begin:
                    source_at_begin = source_at_begin[0]
                    self.add_to("name", [source_at_begin[0] ])
                    if ('###' not in source_at_begin[1] or '===' not in source_at_begin[1]):
                        self.add_to("description", [source_at_begin[1]])
                    if len(source_at_begin[0]) > 2 and '####' not in source_at_begin[2]:
                        self.add_to("targets", [source_at_begin[2]])
                if '==' in comment: # For comments like ==1.==
                    values = re.findall(r'==5\..*?==(.*?)-', comment, flags=re.S|re.M)
                    if values:
                        self.add_to("description", values)
                        self.add_to("name", re.findall(r'==3\.(.*?)==', comment))
                    else:
                        values = re.findall(r'==+\s+(.*?)\n', comment)
                        if values:
                            self.add_to("name", [values[0]])
                        
                elif '-----' in comment and not '//' in comment:    # For comments splitted by -----
                    values = re.findall(r'(.*?)--+', comment,flags= re.S | re.M)
                    if values:
                        self.add_to("name", [values[0]])
                        if len(values) > 1:
                            self.add_to("description", [values[1]])

                if not self.extracted_object["name"]:
                    self.add_to("name", re.findall(r'<h\d.?>(.*?)</h\d>', self.exploit)) # headings

                # All posibilities depending on how they write their code
                self.get_basic_ref()
                self.add_to("refs", re.findall(r'[Ss]ource:\s(.*)', comment))
                self.add_to("refs", re.findall(r'(https?://[^,\'\s\"\]\)]+)', comment))
                self.add_to("refs", re.findall(r'(C[VW]E)-(\d+(-\d+)?)', comment))
                self.add_to("description", re.findall(r'(?:Description|Summary|Product|DESCRIPTION|Desc)\s*:?\s*(.*?)\n\n?', comment))
                self.add_to("description", re.findall(r'Vulnerability\.+:?(.*?)#', comment))
                self.add_to("description", re.findall(r'Vulnerability Details:\s+(.*)', comment))
                self.add_to("description", re.findall(r'Component\s*:\s*(.*)', comment))
                self.add_to("vversion", re.findall(r'Vulnerable version\s*:\s*(.*)', comment))
                self.add_to("vversion", re.findall(r'[^\w/](?:VERSIONS?|Versions?(?:\s*numbers:?\s*-+\n)?)\s*:?\s*(.*\s+.*)', comment))
                self.add_to("vversion", re.findall(r'Affected\s*version\s*:\s*(.*\s*.*)?\s*\w+:', comment))
                self.add_to("name", re.findall(r'[^\w/](?:Title|Name|Topic|Software)\s*:?\s*(.*)', comment))
                self.add_to("name", re.findall(r'^(.*?)<br>', comment))
                self.add_to("name", re.findall(r'Script\.+:?(.*?)#', comment))
                self.add_to("name", re.findall(r'#\s*(\[.*?\])', comment))
                if '##' not in comment:
                    self.add_to("name", re.findall(r'\|\s+\|\s+(.*?)\s+\|\s+\|', comment))
                else:
                    values = re.findall(r'###+\s+(.*?)\s+###+', comment, flags=re.S|re.M)
                    if values:
                        values = values[0]
                        anothers = re.findall(r'\s+(.*)', comment)
                        if anothers and len(anothers) > 2 and '###' not in anothers[2]:
                            self.add_to("name", [anothers[1]])
                            self.add_to("targets", [anothers[2]])
                self.add_to("name", re.findall(r'Vendor:\s*(.*)', comment))
                self.add_to("targets", re.findall(r'(?:Tested|TESTED)\s*(?:on|ON)\s*:\s*(.*)', comment))
        
            URI = self.parse_url()
            self.update_db(URI)
        except Exception as e:
            error, parsed_file = self.found_error(e)
        finally:
            self.update_parsed_obj_db(parsed_file, error)

    def parse_url(self):
        URIs = []
        try:
            URIs.extend(regex.findall(r'value=[\"\']?(?:https?://)?([^<>]+?)[\"\'\s]', self.exploit, timeout=5))
        except TimeoutError: pass
        try:
            URIs.extend(self.get_basic_url())
        except TimeoutError:
            pass
        try:    
            URIs.extend(regex.findall(r'action=[\"\'](?:https?://)?([^>]*?)[\"\']', self.exploit, timeout=5, flags=re.M|re.S))
        except TimeoutError: pass
        try:
            URIs.extend(self.get_method_url())
        except TimeoutError:
            pass
        try:
            construct_uri = regex.findall(r'action=\s*.*?document.*?\+(.*?)\+(.*?)\+(.*?);', self.exploit, timeout=5 )
            for uri_to_construct in construct_uri:
                value1 = re.findall(re.escape(uri_to_construct[0]), self.exploit)[0]
                value2 = re.findall(re.escape(uri_to_construct[1]), self.exploit)[0]
                value3 = re.findall(re.escape(uri_to_construct[2]), self.exploit)[0]

                URIs.extend([value1+value2+value3])        
        except TimeoutError: pass

        return self.extract_url(URIs)


