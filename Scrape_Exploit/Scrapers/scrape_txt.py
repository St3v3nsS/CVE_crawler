import re
import regex
from .scraper import Scraper


class TxtScraper(Scraper):
    def __init__(self, filename=None, name=None, exploit_type=None, title=None, platform=None, exploit=None, mongoclient=None, date=None):
        ext = ['.txt']
        super().__init__(filename, name, exploit_type, title, platform, exploit, mongoclient, date, ext)

    def parse_infos(self):
        if self.is_parsed():
            return

        error = False
        parsed_file = True
        try:
            if self.check_source_at_begin():
                if '#' not in self.source_at_begin[2] or '===' not in self.source_at_begin[2]:
                    self.add_to("description", [self.source_at_begin[2]])
                if len(self.source_at_begin[1]) > 2 and '#' not in self.source_at_begin[3]:
                    self.add_to("targets", [self.source_at_begin[3]])

            self.add_to("refs", 
                re.findall(r'(?:based on|[sS]ee|[vV]isit|[pP]ublished at|[Mm]ore|[sS]ite)\s*:?\s*(.*?)\s', self.exploit))
            self.add_to("refs", re.findall(r'(?:[Aa]dvisory|can be found at|Thanks to.*?|Related URLs|Source|Download|Page|URL|available here)\s*:\s*(.*?)\s', self.exploit))
            self.add_to("refs", re.findall(r'(?:(?:Software|Download)? ?[lL]ink\s*.*?|advisor(?:y|ies))\s*:\s*(.*)', self.exploit))
            self.get_basic_name()
            self.add_to("name", re.findall(r'<[tT][iI][tT][lL][eE]>(.*?)</', self.exploit))
            self.add_to("name", re.findall(r'title=(.*)', self.exploit))
            self.add_to("name", re.findall(r'(?<!\")\s(?<!\w)(?:Title|[Nn]ame|Exploit)\s*:?\s*(.*)', self.exploit))
            if not self.extracted_object["name"]:
                self.add_to("name", re.findall(r'<h1>(.*?)</h1', self.exploit))
            self.add_to("vversion", re.findall(r'Vulnerable\s(?:products|Systems)\s*:\s*\n(.*?)\n\n', self.exploit, flags=re.S))
            self.get_basic_version()
            self.add_to("description", 
                re.findall(r'(?:[Dd]esc(?:ription)?|Summary|About)(?!\w)\s*:?\s*(.*?)\n\s+', self.exploit, flags=re.S | re.M))
            self.add_to("description", re.findall(r'(?:Product|Vendor)\s*:\s*(.*)', self.exploit))
            self.add_to("description", re.findall(r'(?:[iI]nformation|[iI]ntroduction|DESCRIPTION)\s*:?\n=+\n\s?(.*)\s*', self.exploit))
            self.get_basic_ref()
            self.add_to("targets", re.findall(r'(?:[Tt]ested\s*(?:on|with)|Target)\s*:?\s*(.*)', self.exploit))

            URI = self.parse_url()
            self.update_db(URI)

        except Exception as e:
            error, parsed_file = self.found_error(e)
        finally:
            self.update_parsed_obj_db(parsed_file, error)

    def parse_url(self):
        URIs = []

        self.exploit = re.sub(r'\$argv\[\d\]', '/', self.exploit)
        try:
            try:
                URIs.extend(self.get_basic_url())
            except TimeoutError:
                pass
            try:
                URIs.extend(self.get_method_url())
            except TimeoutError:
                pass
            try:
                URIs.extend(regex.findall(r'(\/[\/.a-zA-Z0-9-_\[\]]+)', self.exploit, timeout=5))
            except TimeoutError:
                pass
            try:
                URIs.extend(regex.findall(r'(?:GET|POST|PUT|PATCH|HEAD|EXAMPLE\s*\d+)\s*->\s*(.*)', self.exploit, timeout=5))
            except TimeoutError:
                pass
            try:
                URIs.extend(regex.findall(r'action=\"(.*?)\"', self.exploit, timeout=5))
            except TimeoutError:
                pass

            try:
                URIs.extend(regex.findall(r'([^\d]+\.\w+\?)', self.exploit, timeout=5))
            except TimeoutError:
                pass
        finally:

            return self.extract_url(URIs)
